<!doctype html>
<html lang="zh" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta name="generator" content="Hugo 0.101.0" />

<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">



<link rel="icon" href="http://yiqiyun.sd.cegn.cn/static/assets/images/favicon.ico?v=1632342842" type="image/x-icon">

<title>附表1 | 亿栖云文档</title>

<link href="/css/bulma.css" rel="stylesheet">
<link href="/css/autocomplete.css" rel="stylesheet" />
<link href="/css/copy-to-clipboard.css" rel="stylesheet" />


    



<link rel="preload" href="/scss/console.min.3968935d0a1c8815d0609e047c8c7bddc7781a37538ed1b0cc049f82a7c994c1.css" as="style">
<link href="/scss/console.min.3968935d0a1c8815d0609e047c8c7bddc7781a37538ed1b0cc049f82a7c994c1.css" rel="stylesheet" integrity="">


<script
  src="/js/jquery-2.2.4.js?v=1510299508"
  ></script>
	

<script src="/js/common.js?v=1.3"></script>

  </head>
  <body class="td-page">
    <header>
      <div class="nav-wrapper ">
  <nav class="navbar navmenu"  style="display:none;" >
    <div class="container with-no-position doc-container-width ">
      <div class="navbar-brand" id="search-mobile-logo">
        <a class="navbar-item logo" href="http://www.yiqiyun.net.cn">
          <img src="/images/yiqiyun_logo.png" alt="logo" style="height: 32px;width: 120px;">
        </a>
      </div>
      <div class="media-content column is-centered is-5 search-mobile">
        <form action="/search" method="GET">
          <div class="control has-icons-right docs-search-input">
            <input class="input" id="search-bar" name="q" type="search" placeholder="搜索" autocomplete="off">
            <span class="icon is-right" id="mobile-search">
              <img src="/images/icons/search.svg">
            </span>
          </div>
        </form>
        <a href="javascript:;" class="search-mobile-icon"><img src="/images/icons/search.svg"></a>
      </div>
      <div class="navbar-end is-hidden-mobile header-account">
        <div class="navbar-item">
          <div class="field is-grouped">
            <p class="control navbar-user">
              <a class="nav-item" href="http://www.yiqiyun.cn">服务商门户</a>
            </p>
            <p class="control navbar-user">
              <a class="nav-item" href="http://console.yiqiyun.cn/login">登录</a>
            </p>
            <div class="navbar-user">
              <a class="button is-primary j-signup" href="http://console.yiqiyun.cn/signup/" data-gio="{id:'createPageView',var:{sourceType_var:'导航栏'}}" style="background-color: #55a8fd">注册</a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </nav>
  
  <nav class="navbar navmenu navbar-index">
    <div class="container is-size-7 doc-container-width " data-path="1">


	
	
		

  
  

  
  

  
  

  


	
	




  


	
	
	<a href="/ai/deep_learning/" class="has-text-primary">深度学习平台</a><img class="container_span_space" src="/images/icons/path.svg">
	




  


	
	
	<a href="" class="has-text-primary">操作指南</a><img class="container_span_space" src="/images/icons/path.svg">
	




  



	
	<span class="crumb-last-color">附表1</span>
	



	

</div>


  </nav>
  
</div>
    </header>
    <div class="container td-outer doc-container-width container-min-height">
      <div class="td-main">
		
			<h1 class="console-tree-title">操作指南</h1>
		
        <div class="row flex-xl-nowrap">
		  
          <div class="col-12 col-md-3 col-xl-3 td-sidebar d-print-none td-sidebar-menu">
            





<div id="td-sidebar-menu" class="td-sidebar__inner">
  
  <nav class="collapse td-sidebar-nav pt-2" id="td-section-nav">
    <div class="nav-item dropdown d-block ">
      
      
      













<span class="menu__title--collapse active display-hide"
  data-depth="0">
  深度学习平台
  <span
    class="menu__title--icon down">

  </span>
</span>
<ul class="menu__list active"
  data-data=/deep_learning/ data-link=/ai/deep_learning/manual/model/>
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  产品简介
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/intro/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/intro/intro/"
      class="menu__title  "
      data-depth="1">什么是深度学习平台</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/intro/list/"
      class="menu__title  "
      data-depth="1">产品系列</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/intro/superiority/"
      class="menu__title  "
      data-depth="1">产品优势</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/intro/scene/"
      class="menu__title  "
      data-depth="1">应用场景</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  计费指南
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/billing/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/billing/price/"
      class="menu__title  "
      data-depth="1">计费说明</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  快速入门
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/quickstart/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/quickstart/deploy_app/"
      class="menu__title  "
      data-depth="1">步骤一：部署 Deep Learning 应用</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/quickstart/login_vm/"
      class="menu__title  "
      data-depth="1">步骤二：登录主机</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/quickstart/start_env/"
      class="menu__title  "
      data-depth="1">步骤三：启动训练环境</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse active "
  data-depth="1">
  操作指南
  <span
    class="menu__title--icon down">

  </span>
</span>
<ul class="menu__list active"
  data-data=/manual/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/deploy/"
      class="menu__title  "
      data-depth="1">部署 Deep Learning 服务</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/manual/"
      class="menu__title  "
      data-depth="1">深度学习平台启动指南</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/caffe/"
      class="menu__title  "
      data-depth="1">Caffe 使用指南</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/tensorflow/"
      class="menu__title  "
      data-depth="1">TensorFlow 使用指南</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/pytorch/"
      class="menu__title  "
      data-depth="1">PyTorch 使用指南</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/keras/"
      class="menu__title  "
      data-depth="1">Keras 使用指南</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/testing/"
      class="menu__title  "
      data-depth="1">Deep Learning 性能测试</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/training/"
      class="menu__title  "
      data-depth="1">训练和推理</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/model/"
      class="menu__title active "
      data-depth="1">附表1</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/manual/form/"
      class="menu__title  "
      data-depth="1">附表2</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  常见问题
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/faq/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_01/"
      class="menu__title  more-space"
      data-depth="1">容器中 TensorBoard 或者 jupyter 服务已经启动，如何访问？</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_02/"
      class="menu__title  more-space"
      data-depth="1">为什么在 import tensorflow 的时候显示 no module named tensorflow？</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_03/"
      class="menu__title  more-space"
      data-depth="1">运行 GPU 版容器，为什么会出现错误 libcuda.so.1: cannot open shared object file: No such file or directory？</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_04/"
      class="menu__title  more-space"
      data-depth="1">容器启动后，目录 /root 下可能存在 test/ caffe/ opencv/ nccl/ 等文件夹，可以删除吗？</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_05/"
      class="menu__title  more-space"
      data-depth="1">如何查看深度学习平台的 GPU 使用率？</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_06/"
      class="menu__title  "
      data-depth="1">为什么 TensorBoard UI 加载失败？</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/deep_learning/faq/faq_07/"
      class="menu__title  "
      data-depth="1">pip 安装 Python module 速度比较慢怎么办</a>
  </li>
  
  
</ul>


  
  
</ul>


      
      













<span class="menu__title--collapse  display-hide"
  data-depth="0">
  推理引擎
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list  "
  data-data=/inference/ data-link=/ai/deep_learning/manual/model/>
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  产品简介
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/intro/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/inference/intro/intro/"
      class="menu__title  "
      data-depth="1">什么是推理引擎</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/inference/intro/list/"
      class="menu__title  "
      data-depth="1">部署方式</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/inference/intro/superiority/"
      class="menu__title  "
      data-depth="1">产品优势</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  计费指南
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/billing/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/inference/billing/price/"
      class="menu__title  "
      data-depth="1">计费说明</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse  "
  data-depth="1">
  快速入门
  <span
    class="menu__title--icon right">

  </span>
</span>
<ul class="menu__list "
  data-data=/quickstart/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/inference/quickstart/deploy_app/"
      class="menu__title  "
      data-depth="1">部署 Inference Engine 应用</a>
  </li>
  
  
</ul>


  
  
  
  













<span class="menu__title--collapse active "
  data-depth="1">
  操作指南
  <span
    class="menu__title--icon down">

  </span>
</span>
<ul class="menu__list active"
  data-data=/manual/ data-link=/ai/deep_learning/manual/model/>
  
  
  
  
  
  <li>
    <a href="/ai/inference/manual/depoly_model/"
      class="menu__title  "
      data-depth="1">部署模型</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/inference/manual/use_model/"
      class="menu__title  "
      data-depth="1">使用模型</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/inference/manual/log/"
      class="menu__title  "
      data-depth="1">查看日志</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/inference/manual/testing/"
      class="menu__title  "
      data-depth="1">性能测试</a>
  </li>
  
  
  
  
  
  
  <li>
    <a href="/ai/inference/manual/launching/"
      class="menu__title  "
      data-depth="1">负载均衡</a>
  </li>
  
  
</ul>


  
  
</ul>


      
    </div>
  </nav>
</div>


<script src="/js/sidebar-tree.js"></script>


          </div>
          <div class="d-none col-md-2 d-xl-block d-md-block col-xl-2 td-toc d-print-none">
            


<h3 class="nav-title">本页目录</h3>


<nav id="TableOfContents">
  <ul>
    <li><a href="#模型和数据">模型和数据</a>
      <ul>
        <li><a href="#数据集">数据集</a></li>
        <li><a href="#预训练模型">预训练模型</a></li>
      </ul>
    </li>
  </ul>
</nav>




          </div>
          <main class="col-12 col-md-7 col-xl-7" role="main">
            
  

            
            
            
<div class="td-content">
	<div class="td-sidebar-section-title content-index">
		<img class="is-40x40" src="/images/icons/book-open.svg">
		<h3 class="doc_vice_title">操作指南</h3>
		<a href="javascript:;" class="nav-trigger">&nbsp;<span aria-hidden="true"></span></a>
	</div>
	<div class="td-page-top">
		<h1>附表1</h1>
		






<div class="td-page-meta page-meta-actions ml-2 pb-1 mb-0">







</div>



	</div>
	<div class="page-meta-lastmod text-muted ">
	更新时间 2020-12-01

</div>

	<input type="hidden" id="content_console" value="1">
	
	
	<div class="lead"></div>
	

	
	<h2 id="模型和数据">模型和数据</h2>
<p>为了方便用户使用，我们收集了深度学习常用的数据集，以及一些常用模型的预训练权重，放在对象存储中，用户可直接使用这些数据开始自己的工作，节省下载数据的时间，提高工作效率。</p>
<h3 id="数据集">数据集</h3>
<p>ImageNet</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>地址</th>
<th>URL</th>
<th>尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td>ILSVRC2017 Object localization dataset</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_CLS-LOC.tar.gz">CLS-LOC dataset</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_CLS-LOC.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_CLS-LOC.tar.gz</a></td>
<td>155GB</td>
</tr>
<tr>
<td>ILSVRC2017 Object detection dataset</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_DET.tar.gz">DET dataset</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_DET.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_DET.tar.gz</a></td>
<td>55GB</td>
</tr>
<tr>
<td>ILSVRC2017 Object detection test dataset</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_DET_test_new.tar.gz">DET test dataset</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_DET_test_new.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/imagenet/ILSVRC2017_DET_test_new.tar.gz</a></td>
<td>428MB</td>
</tr>
</tbody>
</table>
<p>COCO</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>地址</th>
<th>数量/尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td>2017 Train Images</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/train2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/train2017.zip</a></td>
<td>118K/18GB</td>
</tr>
<tr>
<td>2017 Val images</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/val2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/val2017.zip</a></td>
<td>5K/1GB</td>
</tr>
<tr>
<td>2017 Test images</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/test2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/test2017.zip</a></td>
<td>41K/6GB</td>
</tr>
<tr>
<td>2017 Unlabeled images</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/unlabeled2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/unlabeled2017.zip</a></td>
<td>123K/19GB</td>
</tr>
<tr>
<td>2017 Train/Val annotations</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/annotations_trainval2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/annotations_trainval2017.zip</a></td>
<td>241MB</td>
</tr>
<tr>
<td>2017 Stuff Train/Val annotations</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/stuff_annotations_trainval2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/stuff_annotations_trainval2017.zip</a></td>
<td>401MB</td>
</tr>
<tr>
<td>2017 Testing Image info</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/image_info_test2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/image_info_test2017.zip</a></td>
<td>1MB</td>
</tr>
<tr>
<td>2017 Unlabeled Image info</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/image_info_unlabeled2017.zip">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/coco/image_info_unlabeled2017.zip</a></td>
<td>4MB</td>
</tr>
</tbody>
</table>
<p>PASCAL VOC</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>地址</th>
<th>尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td>VOC2012 training/validation data</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/VOCtrainval_11-May-2012.tar">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/VOCtrainval_11-May-2012.tar</a></td>
<td>1.86GB</td>
</tr>
<tr>
<td>VOC2012 test data</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/VOC2012test.tar">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/VOC2012test.tar</a></td>
<td>1.72GB</td>
</tr>
<tr>
<td>VOC2012 development kit code and documentation</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/VOCdevkit_18-May-2011.tar">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/VOCdevkit_18-May-2011.tar</a></td>
<td>500KB</td>
</tr>
<tr>
<td>VOC2012 PDF documentation</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/devkit_doc.pdf">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2012/devkit_doc.pdf</a></td>
<td>416KB</td>
</tr>
<tr>
<td>VOC2007 training/validation data</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/VOCtrainval_06-Nov-2007.tar">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/VOCtrainval_06-Nov-2007.tar</a></td>
<td>439MB</td>
</tr>
<tr>
<td>VOC2007 test data</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/VOCtest_06-Nov-2007.tar">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/VOCtest_06-Nov-2007.tar</a></td>
<td>430MB</td>
</tr>
<tr>
<td>VOC2007 development kit code and documentation</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/VOCdevkit_08-Jun-2007.tar">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/VOCdevkit_08-Jun-2007.tar</a></td>
<td>250KB</td>
</tr>
<tr>
<td>VOC2007 PDF documentation</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/devkit_doc_07-Jun-2007.pdf">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/voc/2007/devkit_doc_07-Jun-2007.pdf</a></td>
<td>175KB</td>
</tr>
</tbody>
</table>
<p>OpenSLR</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Category</th>
<th>Summary</th>
<th>Files</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vystadial</td>
<td>Speech</td>
<td>English and Czech data, mirrored from the Vystadial project</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/Vystadial/data_voip_cs.tgz">data_voip_cs.tgz [1.5G]</a><br><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/Vystadial/data_voip_en.tgz">data_voip_en.tgz [2.7G]</a></td>
</tr>
<tr>
<td>TED-LIUM</td>
<td>Speech</td>
<td>English speech recognition training corpus from TED talks, created by Laboratoire d’Informatique de l’Université du Maine (LIUM) (mirrored here)</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/TED-LIUM/TEDLIUM_release1.tar.gz">TEDLIUM_release1.tar.gz [21G]</a></td>
</tr>
<tr>
<td>THCHS-30</td>
<td>Speech</td>
<td>A Free Chinese Speech Corpus Released by CSLT@Tsinghua University</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/THCHS-30/data_thchs30.tgz">data_thchs30.tgz [6.4G]</a><br><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/THCHS-30/test-noise.tgz">test-noise.tgz [1.9G]</a><br><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/THCHS-30/resource.tgz">resource.tgz [24M]</a></td>
</tr>
<tr>
<td>Aishell</td>
<td>Speech</td>
<td>Mandarin data, provided by Beijing Shell Shell Technology Co.,Ltd</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/Aishell/data_aishell.tgz">data_aishell.tgz [15G]</a><br><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/Aishell/resource_aishell.tgz">resource_aishell.tgz [1.2M]</a></td>
</tr>
<tr>
<td>Free ST Chinese Mandarin Corpus</td>
<td>Speech</td>
<td>A free Chinese Mandarin corpus by Surfingtech (<a href="https://www.surfing.ai">www.surfing.ai</a>), containing utterances from 855 speakers, 102600 utterances;</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/openslr/Free%20ST%20Chinese%20Mandarin%20Corpus/ST-CMDS-20170001_1-OS.tar.gz">ST-CMDS-20170001_1-OS.tar.gz [8.2G]</a></td>
</tr>
</tbody>
</table>
<p>VGGFace2</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>地址</th>
<th>尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td>Licence.txt</td>
<td>Licence for VGGFace2 dataset.</td>
<td><a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/licence.txt">http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/licence.txt</a></td>
<td>-</td>
</tr>
<tr>
<td>Readme.txt</td>
<td>README.</td>
<td><a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/Readme.txt">http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/Readme.txt</a></td>
<td>-</td>
</tr>
<tr>
<td>Vggface2_train.tar.gz</td>
<td>36G. Loosely cropped faces for training.</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/vggface2_train.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/vggface2_train.tar.gz</a></td>
<td>36GB</td>
</tr>
<tr>
<td>Vggface2_test.tar.gz</td>
<td>1.9G. Loosely cropped faces for testing.</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/vggface2_test.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/vggface2_test.tar.gz</a></td>
<td>1.9GB</td>
</tr>
<tr>
<td>MD5</td>
<td>MD5.</td>
<td><a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/MD5">http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/MD5</a></td>
<td>-</td>
</tr>
<tr>
<td>Meta.tar.gz</td>
<td>Meta information for VGGFace2 Dataset.</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/meta.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/meta.tar.gz</a></td>
<td>9MB</td>
</tr>
<tr>
<td>BB_Landmark.tar.gz</td>
<td>The information for bounding boxes and 5 facial landmarks referring to the loosely cropped faces.</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/bb_landmark.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/bb_landmark.tar.gz</a></td>
<td>170MB</td>
</tr>
<tr>
<td>Dev_kit.tar.gz</td>
<td>Development kit.</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/dev_kit.tar.gz">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/vggface2/dev_kit.tar.gz</a></td>
<td>3kB</td>
</tr>
</tbody>
</table>
<p>中英文维基百科语料</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>地址</th>
<th>尺寸</th>
</tr>
</thead>
<tbody>
<tr>
<td>zhwiki-latest-pages-articles.xml.bz2</td>
<td>2018年7月23日时最新的中文维基百科语料</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/wiki/zhwiki-latest-pages-articles.xml.bz2">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/wiki/zhwiki-latest-pages-articles.xml.bz2</a></td>
<td>1.5GB</td>
</tr>
<tr>
<td>enwiki-latest-pages-articles.xml.bz2</td>
<td>2018年7月23日时最新的英文维基百科语料</td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/dataset/wiki/enwiki-latest-pages-articles.xml.bz2">https://appcenter-deeplearning.sh1a.qingstor.com/dataset/wiki/enwiki-latest-pages-articles.xml.bz2</a></td>
<td>14.2GB</td>
</tr>
</tbody>
</table>
<h3 id="预训练模型">预训练模型</h3>
<p>TensorFlow-Slim image classification model library</p>
<p><span style="color:red">下表中 Checkpoint 地址均为对象存储地址，可直接下载。</span></p>
<table>
<thead>
<tr>
<th>Model</th>
<th>TF-Slim File</th>
<th>Checkpoint</th>
<th>Top-1 Accuracy</th>
<th>Top-5 Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://arxiv.org/abs/1409.4842v1">Inception V1</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/inception_v1_2016_08_28.tar.gz">inception_v1_2016_08_28.tar.gz</a></td>
<td>69.8</td>
<td>89.6</td>
</tr>
<tr>
<td><a href="http://arxiv.org/abs/1502.03167">Inception V2</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/inception_v1_2016_08_28.tar.gz">inception_v2_2016_08_28.tar.gz</a></td>
<td>73.9</td>
<td>91.8</td>
</tr>
<tr>
<td><a href="http://arxiv.org/abs/1512.00567">Inception V3</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v3.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/inception_v3_2016_08_28.tar.gz">inception_v3_2016_08_28.tar.gz</a></td>
<td>78.0</td>
<td>93.9</td>
</tr>
<tr>
<td><a href="http://arxiv.org/abs/1602.07261">Inception V4</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v4.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/inception_v4_2016_09_09.tar.gz">inception_v4_2016_09_09.tar.gz</a></td>
<td>80.2</td>
<td>95.2</td>
</tr>
<tr>
<td><a href="http://arxiv.org/abs/1602.07261">Inception-ResNet-v2</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/inception_resnet_v2_2016_08_30.tar.gz">inception_resnet_v2_2016_08_30.tar.gz</a></td>
<td>80.4</td>
<td>95.3</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1512.03385">ResNet V1 50</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/resnet_v1_50_2016_08_28.tar.gz">resnet_v1_50_2016_08_28.tar.gz</a></td>
<td>75.2</td>
<td>92.2</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1512.03385">ResNet V1 101</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/resnet_v1_101_2016_08_28.tar.gz">resnet_v1_101_2016_08_28.tar.gz</a></td>
<td>76.4</td>
<td>92.9</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1512.03385">ResNet V1 152</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/resnet_v1_152_2016_08_28.tar.gz">resnet_v1_152_2016_08_28.tar.gz</a></td>
<td>76.8</td>
<td>93.2</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1603.05027">ResNet V2 50</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/resnet_v2_50_2017_04_14.tar.gz">resnet_v2_50_2017_04_14.tar.gz</a></td>
<td>75.6</td>
<td>92.8</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1603.05027">ResNet V2 101</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/resnet_v2_101_2017_04_14.tar.gz">resnet_v2_101_2017_04_14.tar.gz</a></td>
<td>77.0</td>
<td>93.7</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1603.05027">ResNet V2 152</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/resnet_v2_152_2017_04_14.tar.gz">resnet_v2_152_2017_04_14.tar.gz</a></td>
<td>77.8</td>
<td>94.1</td>
</tr>
<tr>
<td><a href="http://arxiv.org/abs/1409.1556.pdf">VGG 16</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/vgg.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/vgg_16_2016_08_28.tar.gz">vgg_16_2016_08_28.tar.gz</a></td>
<td>71.5</td>
<td>89.8</td>
</tr>
<tr>
<td><a href="http://arxiv.org/abs/1409.1556.pdf">VGG 19</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/vgg.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/vgg_19_2016_08_28.tar.gz">vgg_19_2016_08_28.tar.gz</a></td>
<td>71.1</td>
<td>89.8</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1704.04861.pdf">MobileNet_v1_1.0_224</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/mobilenet_v1_1.0_224.tgz">mobilenet_v1_1.0_224.tgz</a></td>
<td>70.9</td>
<td>89.9</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1704.04861.pdf">MobileNet_v1_0.50_160</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/mobilenet_v1_0.5_160.tgz">mobilenet_v1_0.5_160.tgz</a></td>
<td>59.1</td>
<td>81.9</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1704.04861.pdf">MobileNet_v1_0.25_128</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/mobilenet_v1_0.25_128.tgz">mobilenet_v1_0.25_128.tgz</a></td>
<td>41.5</td>
<td>66.3</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1801.04381">MobileNet_v2_1.4_224</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/mobilenet_v2_1.4_224.tgz">mobilenet_v2_1.4_224.tgz</a></td>
<td>74.9</td>
<td>92.5</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1801.04381">MobileNet_v2_1.0_224</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet_v2.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/mobilenet_v2_1.0_224.tgz">mobilenet_v2_1.0_224.tgz</a></td>
<td>71.9</td>
<td>91.0</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1707.07012">NASNet-A_Mobile_224</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/nasnet-a_mobile_04_10_2017.tar.gz">nasnet-a_mobile_04_10_2017.tar.gz</a></td>
<td>74.0</td>
<td>91.6</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1707.07012">NASNet-A_Large_331</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/nasnet-a_large_04_10_2017.tar.gz">nasnet-a_large_04_10_2017.tar.gz</a></td>
<td>82.7</td>
<td>96.2</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1712.00559">PNASNet-5_Large_331</a></td>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/pnasnet.py">Code</a></td>
<td><a href="https://appcenter-deeplearning.sh1a.qingstor.com/models/TensorFlow-Slim%20image%20classification/pnasnet-5_large_2017_12_13.tar.gz">pnasnet-5_large_2017_12_13.tar.gz</a></td>
<td>82.9</td>
<td>96.2</td>
</tr>
</tbody>
</table>

	
	
	<div class="page-meta-pagination border-top">
		
		<a href="/ai/deep_learning/manual/training/" class="prev pl1" title="训练和推理 ">
			上一页: 训练和推理
		</a>
		

		
		<a href="/ai/deep_learning/manual/form/" class="next pr1" title="附表2">
			下一页: 附表2
		</a>
		
	</div>
	<div class="page-meta-pagination_word">
		这篇文档解决了您的问题吗？
		<div class="doc_fix_click fix-background-like" data-flag='1'>
			<span>0</span>
		</div>
		<div class="doc_fix_click fix-background-unlike" data-flag='0'>
			<span>0</span>
		</div>
		<input type="hidden" id="doc_fix_flag" value="0">
	</div>
</div>
<script src="/js/content.js"></script>
<script src="/js/viewer.min.js"></script>
<link rel="stylesheet" href="/css/viewer.min.css">
<script>
	var viewer = new Viewer(document.querySelector('.td-content'), {
		url: 'src'
	})
</script>

          </main>
        </div>
      </div>
    </div>
         
    
<script src="/css/bootstrap.min.js"></script>
<script src="/js/autocomplete/jquery.autocomplete.js"></script>
<script src="/js/navbar.js"></script>
<script src="/js/copy-to-clipboard.js"></script>
</script>






<script src="/js/main.min.7d5b92c4889cf0554b0ea5e2309b0b81b196aa7c9a235632938a25d9fc4d8a7c.js" integrity="sha256-fVuSxIic8FVLDqXiMJsLgbGWqnyaI1Yyk4ol2fxNinw=" crossorigin="anonymous"></script>



  </body>
</html>